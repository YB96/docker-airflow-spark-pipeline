{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8c51c19-1a85-4949-84e5-47d5fa9efce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m\n\u001b[1;32m     10\u001b[0m properties \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpostgres\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassword\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassword\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdriver\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morg.postgresql.Driver\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m }\n\u001b[1;32m     16\u001b[0m df \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mjdbc(url\u001b[38;5;241m=\u001b[39mjdbc_url, table\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretail_sales\u001b[39m\u001b[38;5;124m\"\u001b[39m, properties\u001b[38;5;241m=\u001b[39mproperties)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:959\u001b[0m, in \u001b[0;36mDataFrame.show\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    953\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m    954\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_BOOL\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    955\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(vertical)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m    956\u001b[0m     )\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncate, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m truncate:\n\u001b[0;32m--> 959\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mreadline()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Retail_sales\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.jars\", \"/home/jovyan/jars/postgresql-42.7.2.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "jdbc_url = \"jdbc:postgresql://postgres:5432/sql_book_o_reilly\"\n",
    "properties = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"password\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "df = spark.read.jdbc(url=jdbc_url, table=\"retail_sales\", properties=properties)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8ab5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"retail_sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0602370a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year, to_date, sum as spark_sum , first_value \n",
    "from pyspark.sql.functions import year, sum as _sum, col\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e008f30",
   "metadata": {},
   "source": [
    "### YEAR extract from sales_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad1e663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------------------+---------------+--------------------+----+\n",
      "|sales_month|naics_code|    kind_of_business|reason_for_null|               sales|YEAR|\n",
      "+-----------+----------+--------------------+---------------+--------------------+----+\n",
      "| 1992-01-01|       441|Motor vehicle and...|           NULL|29811.00000000000...|1992|\n",
      "| 1992-01-01|      4411|  Automobile dealers|           NULL|25800.00000000000...|1992|\n",
      "+-----------+----------+--------------------+---------------+--------------------+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"YEAR\",year(to_date(\"sales_month\",\"yyyy-MM\")))\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18b6381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------------------+---------------+--------------------+----+\n",
      "|sales_month|naics_code|    kind_of_business|reason_for_null|               sales|YEAR|\n",
      "+-----------+----------+--------------------+---------------+--------------------+----+\n",
      "| 1992-01-01|       441|Motor vehicle and...|           NULL|29811.00000000000...|1992|\n",
      "| 1992-01-01|      4411|  Automobile dealers|           NULL|25800.00000000000...|1992|\n",
      "+-----------+----------+--------------------+---------------+--------------------+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT sales_month, \" \\\n",
    "\"   naics_code, \" \\\n",
    "\"kind_of_business, \" \\\n",
    "\"reason_for_null,\" \\\n",
    "\"sales,date_part('year',sales_month) as YEAR\" \\\n",
    "\" FROM retail_sales\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f94d4f",
   "metadata": {},
   "source": [
    "### sales per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b8d8ca-12ca-4e4d-b53a-3bca14da1b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|year|         total_sales|\n",
      "+----+--------------------+\n",
      "|1992|15710631.00000000...|\n",
      "|1993|16784256.00000000...|\n",
      "+----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.withColumn(\"year\", year(to_date(\"sales_month\", \"yyyy-MM\"))) \\\n",
    "  .groupBy(\"year\") \\\n",
    "  .agg(spark_sum(\"sales\").alias(\"total_sales\")) \\\n",
    "  .orderBy(\"year\") \\\n",
    "  .show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad1a2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|year|         total_sales|\n",
      "+----+--------------------+\n",
      "|1992|15710631.00000000...|\n",
      "|1993|16784256.00000000...|\n",
      "+----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select date_part('year',sales_month) as year,\" \\\n",
    "\"   sum(sales) as total_sales \" \\\n",
    "\"   from retail_sales \" \\\n",
    "\"   group by 1\" \\\n",
    "\"   order by 1\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f5cc28",
   "metadata": {},
   "source": [
    "### Total Sales per business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea23c111-ea9e-4660-8db1-09cf22b71bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|    kind_of_business|         total_sales|\n",
      "+--------------------+--------------------+\n",
      "|All other gen. me...|1406616.000000000...|\n",
      "|All other home fu...|515039.0000000000...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"kind_of_business\") \\\n",
    "  .agg(spark_sum(\"sales\").alias(\"total_sales\")) \\\n",
    "  .orderBy(\"kind_of_business\") \\\n",
    "  .show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bedc577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|    kind_of_business|         total_sales|\n",
      "+--------------------+--------------------+\n",
      "|All other gen. me...|1406616.000000000...|\n",
      "|All other home fu...|515039.0000000000...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select kind_of_business,\" \\\n",
    "\"   sum(sales) as total_sales \" \\\n",
    "\"   from retail_sales \" \\\n",
    "\"   group by 1\" \\\n",
    "\"   order by 1\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ba1251",
   "metadata": {},
   "source": [
    "### count of different kind of business line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d87d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('kind_of_business').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c4e30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|count(DISTINCT kind_of_business)|\n",
      "+--------------------------------+\n",
      "|                              65|\n",
      "+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(distinct(kind_of_business)) from retail_sales\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212b3bd1",
   "metadata": {},
   "source": [
    "### look at sales at women’s clothing stores and at men’s clothing stores per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6412a690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+\n",
      "|sales_year|    kind_of_business|         total_sales|\n",
      "+----------+--------------------+--------------------+\n",
      "|      1992|Men's clothing st...|10179.00000000000...|\n",
      "|      1992|Women's clothing ...|31815.00000000000...|\n",
      "|      1993|Men's clothing st...|9962.000000000000...|\n",
      "|      1993|Women's clothing ...|32350.00000000000...|\n",
      "|      1994|Men's clothing st...|10032.00000000000...|\n",
      "+----------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_filtered = df.filter(\n",
    "    df.kind_of_business.isin(\"Men's clothing stores\", \"Women's clothing stores\")\n",
    ").withColumn(\"sales_year\", year(\"sales_month\")) \\\n",
    " .groupBy(\"sales_year\", \"kind_of_business\") \\\n",
    " .agg(_sum(\"sales\").alias(\"total_sales\")) \\\n",
    " .orderBy(\"sales_year\", \"kind_of_business\")\n",
    "\n",
    "df_filtered.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece88e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+\n",
      "|sales_year|    kind_of_business|         total_sales|\n",
      "+----------+--------------------+--------------------+\n",
      "|      1992|Men's clothing st...|10179.00000000000...|\n",
      "|      1992|Women's clothing ...|31815.00000000000...|\n",
      "|      1993|Men's clothing st...|9962.000000000000...|\n",
      "|      1993|Women's clothing ...|32350.00000000000...|\n",
      "|      1994|Men's clothing st...|10032.00000000000...|\n",
      "+----------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "    DATE_PART('year', sales_month) AS sales_year,\n",
    "    kind_of_business,\n",
    "    SUM(sales) AS total_sales\n",
    "FROM retail_sales\n",
    "WHERE kind_of_business IN (\n",
    "    \"Men's clothing stores\", \"Women's clothing stores\"\n",
    ")\n",
    "GROUP BY 1, 2\n",
    "ORDER BY 1, 2\n",
    "\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fe6d17",
   "metadata": {},
   "source": [
    "### Pivoting Men's and Women's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33390bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------+-----------------------+\n",
      "|sales_year|Men's clothing stores|Women's clothing stores|\n",
      "+----------+---------------------+-----------------------+\n",
      "|      1992| 10179.00000000000...|   31815.00000000000...|\n",
      "|      1993| 9962.000000000000...|   32350.00000000000...|\n",
      "|      1994| 10032.00000000000...|   30585.00000000000...|\n",
      "|      1995| 9315.000000000000...|   28696.00000000000...|\n",
      "+----------+---------------------+-----------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered.groupBy('sales_year').\\\n",
    "    pivot('kind_of_business').\\\n",
    "    sum('total_sales').\\\n",
    "    orderBy('sales_year').\\\n",
    "    show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defcdbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+\n",
      "|year|          mens_sales|        womens_sales|\n",
      "+----+--------------------+--------------------+\n",
      "|1992|10179.00000000000...|31815.00000000000...|\n",
      "|1993|9962.000000000000...|32350.00000000000...|\n",
      "|1994|10032.00000000000...|30585.00000000000...|\n",
      "|1995|9315.000000000000...|28696.00000000000...|\n",
      "+----+--------------------+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        date_part('year', sales_month) AS year,\n",
    "        SUM(CASE \n",
    "            WHEN kind_of_business = \"Men's clothing stores\" \n",
    "            THEN sales \n",
    "        END) AS mens_sales,\n",
    "        SUM(CASE \n",
    "            WHEN kind_of_business = \"Women's clothing stores\" \n",
    "            THEN sales \n",
    "        END) AS womens_sales\n",
    "    FROM retail_sales\n",
    "    WHERE kind_of_business IN (\"Men's clothing stores\", \"Women's clothing stores\")\n",
    "    GROUP BY year\n",
    "    ORDER BY 1\n",
    "\"\"\").show(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1224673",
   "metadata": {},
   "source": [
    "### transform the sales_month column -- spliting month, date, and year(already done)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d07513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sales_month: date (nullable = true)\n",
      " |-- naics_code: string (nullable = true)\n",
      " |-- kind_of_business: string (nullable = true)\n",
      " |-- reason_for_null: string (nullable = true)\n",
      " |-- sales: decimal(38,18) (nullable = true)\n",
      " |-- YEAR: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5e1f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"month\",F.month(F.col(\"sales_month\")))\n",
    "df_transformed = df.withColumn(\"date\",F.dayofmonth(F.col(\"sales_month\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e630fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------------------+---------------+--------------------+----+-----+----+\n",
      "|sales_month|naics_code|    kind_of_business|reason_for_null|               sales|YEAR|month|date|\n",
      "+-----------+----------+--------------------+---------------+--------------------+----+-----+----+\n",
      "| 1992-01-01|       441|Motor vehicle and...|           NULL|29811.00000000000...|1992|    1|   1|\n",
      "| 1992-01-01|      4411|  Automobile dealers|           NULL|25800.00000000000...|1992|    1|   1|\n",
      "| 1992-01-01|4411, 4412|Automobile and ot...|           NULL|26788.00000000000...|1992|    1|   1|\n",
      "+-----------+----------+--------------------+---------------+--------------------+----+-----+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transformed.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef295f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------------------+---------------+--------------------+----+-----+---+\n",
      "|sales_month|naics_code|    kind_of_business|reason_for_null|               sales|year|month|day|\n",
      "+-----------+----------+--------------------+---------------+--------------------+----+-----+---+\n",
      "| 1992-01-01|       441|Motor vehicle and...|           NULL|29811.00000000000...|1992|    1|  1|\n",
      "| 1992-01-01|      4411|  Automobile dealers|           NULL|25800.00000000000...|1992|    1|  1|\n",
      "| 1992-01-01|4411, 4412|Automobile and ot...|           NULL|26788.00000000000...|1992|    1|  1|\n",
      "+-----------+----------+--------------------+---------------+--------------------+----+-----+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\" \n",
    "\"   SELECT *, \" \\\n",
    "\"       date_part('year',sales_month) as year, \" \\\n",
    "\"       date_part('month',sales_month) as month, \" \\\n",
    "\"       date_part('day',sales_month) as day \" \\\n",
    "\"   FROM retail_sales\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d584b55c",
   "metadata": {},
   "source": [
    "### % of each business line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa53585",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df_transformed.groupBy(\"kind_of_business\").agg(F.sum(\"sales\").alias(\"total_sales\"))\n",
    "total_sum = df_grouped.agg(F.sum(\"total_sales\")).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c6c057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decimal('926212990.000000000000000000')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f12b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+\n",
      "|    kind_of_business|         total_sales|  sales_%|\n",
      "+--------------------+--------------------+---------+\n",
      "|Retail and food s...|118053993.0000000...|12.745900|\n",
      "|Retail sales and ...|107701613.0000000...|11.628200|\n",
      "| Retail sales, total|105580364.0000000...|11.399100|\n",
      "|Retail sales and ...|93509935.00000000...|10.095900|\n",
      "+--------------------+--------------------+---------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_percent = df_grouped.withColumn(\"sales_%\",(F.col(\"total_sales\")/total_sum)*100)\n",
    "df_with_percent.orderBy(F.desc(\"sales_%\")).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a11dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------------+\n",
      "|    kind_of_business|         total_sales|percent_of_total|\n",
      "+--------------------+--------------------+----------------+\n",
      "|Retail and food s...|118053993.0000000...|        0.127459|\n",
      "|Retail sales and ...|107701613.0000000...|        0.116282|\n",
      "| Retail sales, total|105580364.0000000...|        0.113991|\n",
      "|Retail sales and ...|93509935.00000000...|        0.100959|\n",
      "+--------------------+--------------------+----------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    WITH total_cte AS (\n",
    "        SELECT SUM(sales) AS total_amount\n",
    "        FROM retail_sales\n",
    "    )\n",
    "    SELECT \n",
    "        r.kind_of_business,\n",
    "        SUM(r.sales) AS total_sales,\n",
    "        SUM(r.sales) / t.total_amount AS percent_of_total\n",
    "    FROM retail_sales r\n",
    "    CROSS JOIN total_cte t\n",
    "    GROUP BY r.kind_of_business, t.total_amount\n",
    "    ORDER BY percent_of_total desc\n",
    "\"\"\").show(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db8d069",
   "metadata": {},
   "source": [
    "### year-wise percentage of each business line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23346f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------------------------------------------------------------------+--------------------------+---------------------------+-------------+\n",
      "|sales_year|kind_of_business                                                                 |total_sales               |yearly_total               |sales_percent|\n",
      "+----------+---------------------------------------------------------------------------------+--------------------------+---------------------------+-------------+\n",
      "|1992      |Retail and food services sales, total                                            |2014102.000000000000000000|15710631.000000000000000000|12.820000    |\n",
      "|1992      |Retail sales and food services excl gasoline stations                            |1857778.000000000000000000|15710631.000000000000000000|11.825000    |\n",
      "|1992      |Retail sales, total                                                              |1811237.000000000000000000|15710631.000000000000000000|11.528700    |\n",
      "|1992      |Retail sales and food services excl motor vehicle and parts                      |1595709.000000000000000000|15710631.000000000000000000|10.156900    |\n",
      "|1992      |Retail sales and food services excl motor vehicle and parts and gasoline stations|1439385.000000000000000000|15710631.000000000000000000|9.161900     |\n",
      "+----------+---------------------------------------------------------------------------------+--------------------------+---------------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_yearly = df.withColumn(\"sales_year\", F.year(\"sales_month\"))\n",
    "\n",
    "df_grouped = df_yearly.groupBy(\"sales_year\", \"kind_of_business\").agg(F.sum(\"sales\").alias(\"total_sales\"))\n",
    "\n",
    "window = Window.partitionBy(\"sales_year\")\n",
    "df_with_percent = df_grouped.withColumn(\"yearly_total\", F.sum(\"total_sales\").over(window))\n",
    "df_with_percent = df_with_percent.withColumn(\"sales_percent\", (F.col(\"total_sales\") / F.col(\"yearly_total\")) * 100)\n",
    "\n",
    "df_with_percent.orderBy(\"sales_year\", F.desc(\"sales_percent\")).show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afe0348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------------------------+--------------------+-------------+\n",
      "|year|    kind_of_business|total_sales_per_business|        yearly_total|sales_percent|\n",
      "+----+--------------------+------------------------+--------------------+-------------+\n",
      "|1992|Retail and food s...|    2014102.000000000...|15710631.00000000...|    12.820000|\n",
      "|1992|Retail sales and ...|    1857778.000000000...|15710631.00000000...|    11.825000|\n",
      "|1992| Retail sales, total|    1811237.000000000...|15710631.00000000...|    11.528700|\n",
      "|1992|Retail sales and ...|    1595709.000000000...|15710631.00000000...|    10.156900|\n",
      "|1992|Retail sales and ...|    1439385.000000000...|15710631.00000000...|     9.161900|\n",
      "+----+--------------------+------------------------+--------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    WITH yearly_per_business AS (\n",
    "        SELECT\n",
    "            year(sales_month) AS year,\n",
    "            kind_of_business,\n",
    "            SUM(sales) AS total_sales_per_business\n",
    "        FROM retail_sales\n",
    "        GROUP BY 1, 2\n",
    "    ),  \n",
    "    yearly_total_calculation AS (  \n",
    "        SELECT\n",
    "            year,\n",
    "            kind_of_business,\n",
    "            total_sales_per_business,\n",
    "            SUM(total_sales_per_business) OVER (PARTITION BY year) AS yearly_total\n",
    "        FROM yearly_per_business\n",
    "    )\n",
    "    SELECT\n",
    "        year,\n",
    "        kind_of_business,\n",
    "        total_sales_per_business,\n",
    "        yearly_total,\n",
    "        (total_sales_per_business/yearly_total)*100 as sales_percent\n",
    "    FROM yearly_total_calculation\n",
    "    ORDER BY year, total_sales_per_business DESC;\n",
    "\"\"\").show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baca3ed",
   "metadata": {},
   "source": [
    "### INDEXING using the business line of women and men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04255b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------+------------------------+------------------------+-------------------------+\n",
      "|sales_year|kind_of_business       |sales                   |index_sales             |pct_change_with_base_year|\n",
      "+----------+-----------------------+------------------------+------------------------+-------------------------+\n",
      "|1992      |Men's clothing stores  |10179.000000000000000000|10179.000000000000000000|0.000000                 |\n",
      "|1992      |Women's clothing stores|31815.000000000000000000|31815.000000000000000000|0.000000                 |\n",
      "|1993      |Men's clothing stores  |9962.000000000000000000 |10179.000000000000000000|-2.131800                |\n",
      "|1993      |Women's clothing stores|32350.000000000000000000|31815.000000000000000000|1.681600                 |\n",
      "|1994      |Men's clothing stores  |10032.000000000000000000|10179.000000000000000000|-1.444100                |\n",
      "+----------+-----------------------+------------------------+------------------------+-------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_women_and_men = df.filter(\n",
    "    ((F.col(\"kind_of_business\") == \"Women's clothing stores\") |\n",
    "     (F.col(\"kind_of_business\") == \"Men's clothing stores\")) &\n",
    "    (F.col(\"sales_month\") <= F.lit(\"2019-12-31\"))\n",
    ")\n",
    "\n",
    "# Extract sales_year\n",
    "df_yearly_women = df_women_and_men.withColumn(\"sales_year\", F.year(F.col(\"sales_month\")))\n",
    "\n",
    "# Group by sales_year and sum sales\n",
    "df_grouped_women = df_yearly_women.groupBy(\"sales_year\",\"kind_of_business\").agg(F.sum(\"sales\").alias(\"sales\"))\n",
    "\n",
    "# Define the window and apply first_value (partition not needed since it's only one business)\n",
    "window_f = Window.partitionBy(\"kind_of_business\").orderBy(\"sales_year\")\n",
    "\n",
    "# Apply first_value\n",
    "df_first_value_women = df_grouped_women.withColumn(\n",
    "    \"index_sales\", F.first_value(F.col(\"sales\")).over(window_f)\n",
    ")\n",
    "\n",
    "# Percent change with base year\n",
    "df_women_pct_change = df_first_value_women.withColumn(\n",
    "    \"pct_change_with_base_year\",\n",
    "    ((F.col(\"sales\") / F.col(\"index_sales\")) - 1) * 100\n",
    ")\n",
    "\n",
    "df_women_pct_change.orderBy(\"sales_year\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e49dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+--------------+\n",
      "|sales_year|               sales|    kind_of_business|pct_from_index|\n",
      "+----------+--------------------+--------------------+--------------+\n",
      "|      1992|10179.00000000000...|Men's clothing st...|      0.000000|\n",
      "|      1992|31815.00000000000...|Women's clothing ...|      0.000000|\n",
      "|      1993|9962.000000000000...|Men's clothing st...|     -2.131800|\n",
      "|      1993|32350.00000000000...|Women's clothing ...|      1.681600|\n",
      "|      1994|10032.00000000000...|Men's clothing st...|     -1.444100|\n",
      "+----------+--------------------+--------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "          sales_year, \n",
    "          sales,\n",
    "          kind_of_business,\n",
    "          ((sales / first_value(sales) OVER (PARTITION BY kind_of_business ORDER BY sales_year)) - 1) * 100 \n",
    "              AS pct_from_index\n",
    "    FROM (\n",
    "         SELECT \n",
    "             year(sales_month) AS sales_year,\n",
    "             kind_of_business,\n",
    "             SUM(sales) AS sales\n",
    "         FROM retail_sales\n",
    "         WHERE kind_of_business IN (\"Men's clothing stores\",\"Women's clothing stores\")\n",
    "           AND sales_month <= '2019-12-31'\n",
    "         GROUP BY year(sales_month), kind_of_business\n",
    "    ) a\n",
    "    ORDER BY 1\n",
    "\"\"\").show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17393dc",
   "metadata": {},
   "source": [
    "### Rolling Time Windows\n",
    "\n",
    "use a window of 12 months to get rolling annual sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85e5900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------------+-------------------+-----------------------+\n",
      "|sales_month|sales                  |rolling_sales_month|rolling_sales          |\n",
      "+-----------+-----------------------+-------------------+-----------------------+\n",
      "|2019-12-01 |4496.000000000000000000|2019-01-01         |2511.000000000000000000|\n",
      "|2019-12-01 |4496.000000000000000000|2019-02-01         |2680.000000000000000000|\n",
      "|2019-12-01 |4496.000000000000000000|2019-03-01         |3585.000000000000000000|\n",
      "|2019-12-01 |4496.000000000000000000|2019-04-01         |3604.000000000000000000|\n",
      "|2019-12-01 |4496.000000000000000000|2019-05-01         |3807.000000000000000000|\n",
      "|2019-12-01 |4496.000000000000000000|2019-06-01         |3272.000000000000000000|\n",
      "|2019-12-01 |4496.000000000000000000|2019-07-01         |3261.000000000000000000|\n",
      "|2019-12-01 |4496.000000000000000000|2019-08-01         |3325.000000000000000000|\n",
      "|2019-12-01 |4496.000000000000000000|2019-09-01         |3080.000000000000000000|\n",
      "|2019-12-01 |4496.000000000000000000|2019-10-01         |3390.000000000000000000|\n",
      "|2019-12-01 |4496.000000000000000000|2019-11-01         |3850.000000000000000000|\n",
      "|2019-12-01 |4496.000000000000000000|2019-12-01         |4496.000000000000000000|\n",
      "+-----------+-----------------------+-------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Filter for Women's clothing stores\n",
    "df_women = df.filter(F.col(\"kind_of_business\") == \"Women's clothing stores\") \\\n",
    "             .withColumn(\"sales_month\", F.to_date(\"sales_month\"))\n",
    "\n",
    "# Anchor month\n",
    "anchor_month = \"2019-12-01\"\n",
    "\n",
    "# Get sales for anchor month\n",
    "anchor_df = df_women.filter(F.col(\"sales_month\") == anchor_month) \\\n",
    "    .select(\n",
    "        F.col(\"sales_month\").alias(\"sales_month\"),\n",
    "        F.col(\"sales\").alias(\"sales\")\n",
    "    )\n",
    "\n",
    "# Get rolling months (last 12 months from anchor)\n",
    "rolling_df = df_women.filter(\n",
    "    (F.col(\"sales_month\") <= anchor_month) &\n",
    "    (F.col(\"sales_month\") >= F.add_months(F.lit(anchor_month), -11))\n",
    ").select(\n",
    "    F.col(\"sales_month\").alias(\"rolling_sales_month\"),\n",
    "    F.col(\"sales\").alias(\"rolling_sales\")\n",
    ")\n",
    "\n",
    "# Cross join anchor month with rolling months (to simulate SQL join)\n",
    "result = anchor_df.crossJoin(rolling_df)\n",
    "\n",
    "result.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34679b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------------------+--------------------+\n",
      "|sales_month|               sales|rolling_sales_month|       rolling_sales|\n",
      "+-----------+--------------------+-------------------+--------------------+\n",
      "| 2019-12-01|4496.000000000000...|         2019-01-01|2511.000000000000...|\n",
      "| 2019-12-01|4496.000000000000...|         2019-02-01|2680.000000000000...|\n",
      "| 2019-12-01|4496.000000000000...|         2019-03-01|3585.000000000000...|\n",
      "| 2019-12-01|4496.000000000000...|         2019-04-01|3604.000000000000...|\n",
      "| 2019-12-01|4496.000000000000...|         2019-05-01|3807.000000000000...|\n",
      "| 2019-12-01|4496.000000000000...|         2019-06-01|3272.000000000000...|\n",
      "| 2019-12-01|4496.000000000000...|         2019-07-01|3261.000000000000...|\n",
      "| 2019-12-01|4496.000000000000...|         2019-08-01|3325.000000000000...|\n",
      "| 2019-12-01|4496.000000000000...|         2019-09-01|3080.000000000000...|\n",
      "| 2019-12-01|4496.000000000000...|         2019-10-01|3390.000000000000...|\n",
      "| 2019-12-01|4496.000000000000...|         2019-11-01|3850.000000000000...|\n",
      "| 2019-12-01|4496.000000000000...|         2019-12-01|4496.000000000000...|\n",
      "+-----------+--------------------+-------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT a.sales_month\n",
    ",a.sales\n",
    ",b.sales_month as rolling_sales_month\n",
    ",b.sales as rolling_sales\n",
    "FROM retail_sales a\n",
    "JOIN retail_sales b on a.kind_of_business = b.kind_of_business\n",
    " and b.sales_month between a.sales_month - interval '11 months'\n",
    " and a.sales_month\n",
    " and b.kind_of_business = \"Women's clothing stores\"\n",
    "WHERE a.kind_of_business = \"Women's clothing stores\"\n",
    "and a.sales_month = '2019-12-01'\n",
    ";\n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261cb771",
   "metadata": {},
   "source": [
    "### Monthly sales and 12-month moving average sales for women’s clothing stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dda7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------------+\n",
      "|sales_month|          moving_avg|records_count|\n",
      "+-----------+--------------------+-------------+\n",
      "| 1992-01-01|1873.000000000000...|            1|\n",
      "| 1992-02-01|1932.000000000000...|            2|\n",
      "| 1992-03-01|2089.000000000000...|            3|\n",
      "| 1992-04-01|2233.000000000000...|            4|\n",
      "+-----------+--------------------+-------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window_spec = (\n",
    "    Window\n",
    "    .orderBy(\"sales_month\")\n",
    "    .rowsBetween(-11, 0)   # 11 preceding rows + current row\n",
    ")\n",
    "\n",
    "df_result = (\n",
    "    df\n",
    "    .filter(F.col(\"kind_of_business\") == \"Women's clothing stores\")\n",
    "    .withColumn(\"moving_avg\", F.avg(\"sales\").over(window_spec))\n",
    "    .withColumn(\"records_count\", F.count(\"sales\").over(window_spec))\n",
    "    .select(\"sales_month\",\"moving_avg\",\"records_count\")\n",
    ")\n",
    "df_result.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694d59a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------------+\n",
      "|sales_month|          moving_avg|records_count|\n",
      "+-----------+--------------------+-------------+\n",
      "| 1992-01-01|1873.000000000000...|            1|\n",
      "| 1992-02-01|1932.000000000000...|            2|\n",
      "| 1992-03-01|2089.000000000000...|            3|\n",
      "| 1992-04-01|2233.000000000000...|            4|\n",
      "+-----------+--------------------+-------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT \n",
    "          sales_month,\n",
    "          avg(sales) over (order by sales_month rows between 11 preceding and current row) as moving_avg,\n",
    "          count(sales) over (order by sales_month rows between 11 preceding and current row) as records_count\n",
    "FROM retail_sales\n",
    "WHERE kind_of_business = \"Women's clothing stores\"\n",
    ";\n",
    "          \"\"\").show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cef93af",
   "metadata": {},
   "source": [
    "### Rolling Time Windows with Sparse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1493af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+------------+-----------+-----------+---------+--------------+-----------+-------------+----------+------------+----------+----------------+------------------+-----------------+--------------+------------+--------------------+-------------------+----+------+-------+\n",
      "|      date|date_key|day_of_month|day_of_year|day_of_week| day_name|day_short_name|week_number|week_of_month|      week|month_number|month_name|month_short_name|first_day_of_month|last_day_of_month|quarter_number|quarter_name|first_day_of_quarter|last_day_of_quarter|year|decade|century|\n",
      "+----------+--------+------------+-----------+-----------+---------+--------------+-----------+-------------+----------+------------+----------+----------------+------------------+-----------------+--------------+------------+--------------------+-------------------+----+------+-------+\n",
      "|1770-01-01|17700101|           1|          1|          1|   Monday|           Mon|          1|            1|1770-01-01|           1|   January|             Jan|        1770-01-01|       1770-01-31|             1|          Q1|          1770-01-01|         1770-03-31|1770|  1770|     18|\n",
      "|1770-01-02|17700102|           2|          2|          2|  Tuesday|           Tue|          1|            1|1770-01-01|           1|   January|             Jan|        1770-01-01|       1770-01-31|             1|          Q1|          1770-01-01|         1770-03-31|1770|  1770|     18|\n",
      "|1770-01-03|17700103|           3|          3|          3|Wednesday|           Wed|          1|            1|1770-01-01|           1|   January|             Jan|        1770-01-01|       1770-01-31|             1|          Q1|          1770-01-01|         1770-03-31|1770|  1770|     18|\n",
      "|1770-01-04|17700104|           4|          4|          4| Thursday|           Thu|          1|            1|1770-01-01|           1|   January|             Jan|        1770-01-01|       1770-01-31|             1|          Q1|          1770-01-01|         1770-03-31|1770|  1770|     18|\n",
      "|1770-01-05|17700105|           5|          5|          5|   Friday|           Fri|          1|            1|1770-01-01|           1|   January|             Jan|        1770-01-01|       1770-01-31|             1|          Q1|          1770-01-01|         1770-03-31|1770|  1770|     18|\n",
      "+----------+--------+------------+-----------+-----------+---------+--------------+-----------+-------------+----------+------------+----------+----------------+------------------+-----------------+--------------+------------+--------------------+-------------------+----+------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets pull the date_dim table from postgres or csv \n",
    "df_date = spark.read.jdbc(url=jdbc_url, table=\"date_dim\", properties=properties)\n",
    "df_date.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246c955b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-----------------------+\n",
      "|date      |sales_month|sales                  |\n",
      "+----------+-----------+-----------------------+\n",
      "|1993-01-01|1992-07-01 |2373.000000000000000000|\n",
      "|1993-01-01|1993-01-01 |2123.000000000000000000|\n",
      "|1993-02-01|1992-07-01 |2373.000000000000000000|\n",
      "|1993-02-01|1993-01-01 |2123.000000000000000000|\n",
      "|1993-03-01|1992-07-01 |2373.000000000000000000|\n",
      "+----------+-----------+-----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "#Filter retail_sales \n",
    "retail_sales_filtered = (\n",
    "    df\n",
    "    .filter(\n",
    "        (F.col(\"kind_of_business\") == \"Women's clothing stores\") &\n",
    "        (F.month(\"sales_month\").isin([1, 7]))\n",
    "    )\n",
    "    .select(\"sales_month\", \"sales\")\n",
    ")\n",
    "\n",
    "# Step 2: Filter date_dim \n",
    "date_dim_filtered = (\n",
    "    df_date\n",
    "    .filter(\n",
    "        (F.col(\"date\") == F.col(\"first_day_of_month\")) &\n",
    "        (F.col(\"date\").between(\"1993-01-01\", \"2020-12-01\"))\n",
    "    )\n",
    ")\n",
    "\n",
    "# Step 3: Join condition\n",
    "joined_df = (\n",
    "    date_dim_filtered.alias(\"a\")\n",
    "    .join(\n",
    "        retail_sales_filtered.alias(\"b\"),\n",
    "        (F.col(\"b.sales_month\").between(F.add_months(F.col(\"a.date\"), -11), F.col(\"a.date\"))),\"inner\")\n",
    "    .select(\"a.date\", \"b.sales_month\", \"b.sales\")\n",
    ")\n",
    "\n",
    "# Final result\n",
    "joined_df.show(5, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d606aa0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------------------+--------------------+\n",
      "|sales_month|               sales|rolling_sales_month|       rolling_sales|\n",
      "+-----------+--------------------+-------------------+--------------------+\n",
      "| 2019-12-01|4496.000000000000...|         2019-01-01|2511.000000000000...|\n",
      "| 2019-12-01|4496.000000000000...|         2019-02-01|2680.000000000000...|\n",
      "| 2019-12-01|4496.000000000000...|         2019-03-01|3585.000000000000...|\n",
      "| 2019-12-01|4496.000000000000...|         2019-04-01|3604.000000000000...|\n",
      "| 2019-12-01|4496.000000000000...|         2019-05-01|3807.000000000000...|\n",
      "+-----------+--------------------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "        SELECT \n",
    "                a.sales_month\n",
    "                ,a.sales\n",
    "                ,b.sales_month as rolling_sales_month\n",
    "                ,b.sales as rolling_sales\n",
    "        FROM retail_sales a\n",
    "        JOIN retail_sales b on a.kind_of_business = b.kind_of_business\n",
    "                and b.sales_month between a.sales_month - interval '11 months'\n",
    "                and a.sales_month\n",
    "                and b.kind_of_business = \"Women's clothing stores\"\n",
    "        WHERE a.kind_of_business = \"Women's clothing stores\"\n",
    "                and a.sales_month = '2019-12-01'\n",
    ";\n",
    "  \"\"\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97b583f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
